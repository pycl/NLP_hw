{
  "best_global_step": 11869,
  "best_metric": 0.5283420085906982,
  "best_model_checkpoint": "./results\\checkpoint-11869",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 11869,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008425309630128908,
      "grad_norm": 4.016661167144775,
      "learning_rate": 9.900000000000002e-06,
      "loss": 1.1413,
      "step": 100
    },
    {
      "epoch": 0.016850619260257816,
      "grad_norm": 1.3187956809997559,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 1.1003,
      "step": 200
    },
    {
      "epoch": 0.025275928890386722,
      "grad_norm": 1.0502922534942627,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 1.0468,
      "step": 300
    },
    {
      "epoch": 0.03370123852051563,
      "grad_norm": 1.9944931268692017,
      "learning_rate": 3.99e-05,
      "loss": 0.9936,
      "step": 400
    },
    {
      "epoch": 0.04212654815064454,
      "grad_norm": 2.670973539352417,
      "learning_rate": 4.99e-05,
      "loss": 0.959,
      "step": 500
    },
    {
      "epoch": 0.050551857780773445,
      "grad_norm": 3.7028896808624268,
      "learning_rate": 4.9564605506201075e-05,
      "loss": 0.8971,
      "step": 600
    },
    {
      "epoch": 0.05897716741090235,
      "grad_norm": 3.5397000312805176,
      "learning_rate": 4.912481308822236e-05,
      "loss": 0.8466,
      "step": 700
    },
    {
      "epoch": 0.06740247704103126,
      "grad_norm": 2.8675973415374756,
      "learning_rate": 4.8685020670243646e-05,
      "loss": 0.8277,
      "step": 800
    },
    {
      "epoch": 0.07582778667116016,
      "grad_norm": 2.910862445831299,
      "learning_rate": 4.824522825226493e-05,
      "loss": 0.7865,
      "step": 900
    },
    {
      "epoch": 0.08425309630128908,
      "grad_norm": 2.386852741241455,
      "learning_rate": 4.780543583428622e-05,
      "loss": 0.7697,
      "step": 1000
    },
    {
      "epoch": 0.09267840593141798,
      "grad_norm": 8.2190580368042,
      "learning_rate": 4.73656434163075e-05,
      "loss": 0.7319,
      "step": 1100
    },
    {
      "epoch": 0.10110371556154689,
      "grad_norm": 3.381404399871826,
      "learning_rate": 4.6925850998328794e-05,
      "loss": 0.7299,
      "step": 1200
    },
    {
      "epoch": 0.10952902519167579,
      "grad_norm": 4.317290782928467,
      "learning_rate": 4.648605858035008e-05,
      "loss": 0.6951,
      "step": 1300
    },
    {
      "epoch": 0.1179543348218047,
      "grad_norm": 5.630881309509277,
      "learning_rate": 4.6050664086551145e-05,
      "loss": 0.7019,
      "step": 1400
    },
    {
      "epoch": 0.12637964445193361,
      "grad_norm": 7.663987636566162,
      "learning_rate": 4.561087166857244e-05,
      "loss": 0.6809,
      "step": 1500
    },
    {
      "epoch": 0.13480495408206253,
      "grad_norm": 6.437908172607422,
      "learning_rate": 4.517107925059372e-05,
      "loss": 0.68,
      "step": 1600
    },
    {
      "epoch": 0.1432302637121914,
      "grad_norm": 5.66786527633667,
      "learning_rate": 4.473128683261501e-05,
      "loss": 0.6594,
      "step": 1700
    },
    {
      "epoch": 0.15165557334232033,
      "grad_norm": 3.5117030143737793,
      "learning_rate": 4.429149441463629e-05,
      "loss": 0.6163,
      "step": 1800
    },
    {
      "epoch": 0.16008088297244924,
      "grad_norm": 3.6635539531707764,
      "learning_rate": 4.385170199665758e-05,
      "loss": 0.6391,
      "step": 1900
    },
    {
      "epoch": 0.16850619260257815,
      "grad_norm": 4.319108009338379,
      "learning_rate": 4.3411909578678864e-05,
      "loss": 0.6491,
      "step": 2000
    },
    {
      "epoch": 0.17693150223270704,
      "grad_norm": 6.051564693450928,
      "learning_rate": 4.2972117160700156e-05,
      "loss": 0.6303,
      "step": 2100
    },
    {
      "epoch": 0.18535681186283595,
      "grad_norm": 2.7620725631713867,
      "learning_rate": 4.2532324742721434e-05,
      "loss": 0.6239,
      "step": 2200
    },
    {
      "epoch": 0.19378212149296486,
      "grad_norm": 4.452475070953369,
      "learning_rate": 4.209253232474272e-05,
      "loss": 0.6342,
      "step": 2300
    },
    {
      "epoch": 0.20220743112309378,
      "grad_norm": 6.505082607269287,
      "learning_rate": 4.165273990676401e-05,
      "loss": 0.6425,
      "step": 2400
    },
    {
      "epoch": 0.2106327407532227,
      "grad_norm": 4.366857051849365,
      "learning_rate": 4.12129474887853e-05,
      "loss": 0.6045,
      "step": 2500
    },
    {
      "epoch": 0.21905805038335158,
      "grad_norm": 5.5176262855529785,
      "learning_rate": 4.077315507080658e-05,
      "loss": 0.5957,
      "step": 2600
    },
    {
      "epoch": 0.2274833600134805,
      "grad_norm": 4.763883113861084,
      "learning_rate": 4.033336265282787e-05,
      "loss": 0.5733,
      "step": 2700
    },
    {
      "epoch": 0.2359086696436094,
      "grad_norm": 4.482470989227295,
      "learning_rate": 3.989357023484915e-05,
      "loss": 0.62,
      "step": 2800
    },
    {
      "epoch": 0.24433397927373832,
      "grad_norm": 5.438982009887695,
      "learning_rate": 3.945377781687044e-05,
      "loss": 0.6106,
      "step": 2900
    },
    {
      "epoch": 0.25275928890386723,
      "grad_norm": 3.987403154373169,
      "learning_rate": 3.901398539889172e-05,
      "loss": 0.593,
      "step": 3000
    },
    {
      "epoch": 0.2611845985339961,
      "grad_norm": 4.303983688354492,
      "learning_rate": 3.857419298091301e-05,
      "loss": 0.5999,
      "step": 3100
    },
    {
      "epoch": 0.26960990816412506,
      "grad_norm": 6.196983814239502,
      "learning_rate": 3.8134400562934294e-05,
      "loss": 0.6044,
      "step": 3200
    },
    {
      "epoch": 0.27803521779425394,
      "grad_norm": 5.846596717834473,
      "learning_rate": 3.7694608144955586e-05,
      "loss": 0.592,
      "step": 3300
    },
    {
      "epoch": 0.2864605274243828,
      "grad_norm": 2.9212589263916016,
      "learning_rate": 3.725921365115665e-05,
      "loss": 0.6308,
      "step": 3400
    },
    {
      "epoch": 0.29488583705451177,
      "grad_norm": 4.913599967956543,
      "learning_rate": 3.6819421233177944e-05,
      "loss": 0.5764,
      "step": 3500
    },
    {
      "epoch": 0.30331114668464065,
      "grad_norm": 3.392059803009033,
      "learning_rate": 3.637962881519923e-05,
      "loss": 0.6188,
      "step": 3600
    },
    {
      "epoch": 0.3117364563147696,
      "grad_norm": 3.2589852809906006,
      "learning_rate": 3.593983639722051e-05,
      "loss": 0.5762,
      "step": 3700
    },
    {
      "epoch": 0.3201617659448985,
      "grad_norm": 5.733110427856445,
      "learning_rate": 3.55000439792418e-05,
      "loss": 0.5849,
      "step": 3800
    },
    {
      "epoch": 0.32858707557502737,
      "grad_norm": 4.449450492858887,
      "learning_rate": 3.5060251561263085e-05,
      "loss": 0.5904,
      "step": 3900
    },
    {
      "epoch": 0.3370123852051563,
      "grad_norm": 3.6194093227386475,
      "learning_rate": 3.462045914328437e-05,
      "loss": 0.6128,
      "step": 4000
    },
    {
      "epoch": 0.3454376948352852,
      "grad_norm": 5.36473274230957,
      "learning_rate": 3.418066672530566e-05,
      "loss": 0.5602,
      "step": 4100
    },
    {
      "epoch": 0.3538630044654141,
      "grad_norm": 4.290599346160889,
      "learning_rate": 3.374087430732694e-05,
      "loss": 0.5594,
      "step": 4200
    },
    {
      "epoch": 0.362288314095543,
      "grad_norm": 3.067939043045044,
      "learning_rate": 3.3301081889348226e-05,
      "loss": 0.572,
      "step": 4300
    },
    {
      "epoch": 0.3707136237256719,
      "grad_norm": 4.971569061279297,
      "learning_rate": 3.286128947136952e-05,
      "loss": 0.6027,
      "step": 4400
    },
    {
      "epoch": 0.37913893335580084,
      "grad_norm": 3.618701696395874,
      "learning_rate": 3.2421497053390804e-05,
      "loss": 0.5711,
      "step": 4500
    },
    {
      "epoch": 0.38756424298592973,
      "grad_norm": 8.048070907592773,
      "learning_rate": 3.198170463541208e-05,
      "loss": 0.605,
      "step": 4600
    },
    {
      "epoch": 0.3959895526160586,
      "grad_norm": 5.35862922668457,
      "learning_rate": 3.1541912217433374e-05,
      "loss": 0.5795,
      "step": 4700
    },
    {
      "epoch": 0.40441486224618756,
      "grad_norm": 6.899586200714111,
      "learning_rate": 3.110211979945466e-05,
      "loss": 0.5776,
      "step": 4800
    },
    {
      "epoch": 0.41284017187631644,
      "grad_norm": 3.385619878768921,
      "learning_rate": 3.0662327381475945e-05,
      "loss": 0.5674,
      "step": 4900
    },
    {
      "epoch": 0.4212654815064454,
      "grad_norm": 5.659704208374023,
      "learning_rate": 3.022253496349723e-05,
      "loss": 0.5756,
      "step": 5000
    },
    {
      "epoch": 0.42969079113657427,
      "grad_norm": 6.46157693862915,
      "learning_rate": 2.9782742545518515e-05,
      "loss": 0.5685,
      "step": 5100
    },
    {
      "epoch": 0.43811610076670315,
      "grad_norm": 3.4566822052001953,
      "learning_rate": 2.9342950127539804e-05,
      "loss": 0.5934,
      "step": 5200
    },
    {
      "epoch": 0.4465414103968321,
      "grad_norm": 6.962528228759766,
      "learning_rate": 2.890315770956109e-05,
      "loss": 0.5738,
      "step": 5300
    },
    {
      "epoch": 0.454966720026961,
      "grad_norm": 8.938491821289062,
      "learning_rate": 2.8467763215762162e-05,
      "loss": 0.5499,
      "step": 5400
    },
    {
      "epoch": 0.4633920296570899,
      "grad_norm": 5.580460548400879,
      "learning_rate": 2.8027970797783448e-05,
      "loss": 0.5565,
      "step": 5500
    },
    {
      "epoch": 0.4718173392872188,
      "grad_norm": 6.675159931182861,
      "learning_rate": 2.7588178379804736e-05,
      "loss": 0.5558,
      "step": 5600
    },
    {
      "epoch": 0.4802426489173477,
      "grad_norm": 6.691080570220947,
      "learning_rate": 2.7148385961826018e-05,
      "loss": 0.5599,
      "step": 5700
    },
    {
      "epoch": 0.48866795854747663,
      "grad_norm": 7.090754985809326,
      "learning_rate": 2.6708593543847304e-05,
      "loss": 0.5494,
      "step": 5800
    },
    {
      "epoch": 0.4970932681776055,
      "grad_norm": 3.0817956924438477,
      "learning_rate": 2.6268801125868592e-05,
      "loss": 0.5705,
      "step": 5900
    },
    {
      "epoch": 0.5055185778077345,
      "grad_norm": 8.735201835632324,
      "learning_rate": 2.5829008707889877e-05,
      "loss": 0.5827,
      "step": 6000
    },
    {
      "epoch": 0.5139438874378633,
      "grad_norm": 3.1105751991271973,
      "learning_rate": 2.538921628991116e-05,
      "loss": 0.5635,
      "step": 6100
    },
    {
      "epoch": 0.5223691970679922,
      "grad_norm": 6.842557430267334,
      "learning_rate": 2.4949423871932448e-05,
      "loss": 0.5927,
      "step": 6200
    },
    {
      "epoch": 0.5307945066981211,
      "grad_norm": 4.086083889007568,
      "learning_rate": 2.4509631453953737e-05,
      "loss": 0.5645,
      "step": 6300
    },
    {
      "epoch": 0.5392198163282501,
      "grad_norm": 5.635257244110107,
      "learning_rate": 2.406983903597502e-05,
      "loss": 0.5488,
      "step": 6400
    },
    {
      "epoch": 0.547645125958379,
      "grad_norm": 4.589574813842773,
      "learning_rate": 2.3630046617996307e-05,
      "loss": 0.5581,
      "step": 6500
    },
    {
      "epoch": 0.5560704355885079,
      "grad_norm": 3.366285562515259,
      "learning_rate": 2.3190254200017592e-05,
      "loss": 0.549,
      "step": 6600
    },
    {
      "epoch": 0.5644957452186368,
      "grad_norm": 2.5148520469665527,
      "learning_rate": 2.2750461782038878e-05,
      "loss": 0.5648,
      "step": 6700
    },
    {
      "epoch": 0.5729210548487657,
      "grad_norm": 4.842416763305664,
      "learning_rate": 2.2310669364060166e-05,
      "loss": 0.5403,
      "step": 6800
    },
    {
      "epoch": 0.5813463644788947,
      "grad_norm": 3.091099739074707,
      "learning_rate": 2.187087694608145e-05,
      "loss": 0.5363,
      "step": 6900
    },
    {
      "epoch": 0.5897716741090235,
      "grad_norm": 4.843409061431885,
      "learning_rate": 2.1435482452282525e-05,
      "loss": 0.534,
      "step": 7000
    },
    {
      "epoch": 0.5981969837391524,
      "grad_norm": 6.255495548248291,
      "learning_rate": 2.099569003430381e-05,
      "loss": 0.5846,
      "step": 7100
    },
    {
      "epoch": 0.6066222933692813,
      "grad_norm": 5.3696608543396,
      "learning_rate": 2.0555897616325095e-05,
      "loss": 0.5359,
      "step": 7200
    },
    {
      "epoch": 0.6150476029994102,
      "grad_norm": 7.607211589813232,
      "learning_rate": 2.0116105198346384e-05,
      "loss": 0.549,
      "step": 7300
    },
    {
      "epoch": 0.6234729126295392,
      "grad_norm": 9.59334659576416,
      "learning_rate": 1.9676312780367666e-05,
      "loss": 0.5553,
      "step": 7400
    },
    {
      "epoch": 0.6318982222596681,
      "grad_norm": 7.618631839752197,
      "learning_rate": 1.9236520362388954e-05,
      "loss": 0.5562,
      "step": 7500
    },
    {
      "epoch": 0.640323531889797,
      "grad_norm": 4.625813007354736,
      "learning_rate": 1.879672794441024e-05,
      "loss": 0.5427,
      "step": 7600
    },
    {
      "epoch": 0.6487488415199258,
      "grad_norm": 4.156375885009766,
      "learning_rate": 1.8356935526431525e-05,
      "loss": 0.5352,
      "step": 7700
    },
    {
      "epoch": 0.6571741511500547,
      "grad_norm": 2.9204437732696533,
      "learning_rate": 1.791714310845281e-05,
      "loss": 0.5442,
      "step": 7800
    },
    {
      "epoch": 0.6655994607801837,
      "grad_norm": 5.394432067871094,
      "learning_rate": 1.74773506904741e-05,
      "loss": 0.5429,
      "step": 7900
    },
    {
      "epoch": 0.6740247704103126,
      "grad_norm": 5.5568528175354,
      "learning_rate": 1.703755827249538e-05,
      "loss": 0.5311,
      "step": 8000
    },
    {
      "epoch": 0.6824500800404415,
      "grad_norm": 4.98527717590332,
      "learning_rate": 1.659776585451667e-05,
      "loss": 0.5586,
      "step": 8100
    },
    {
      "epoch": 0.6908753896705704,
      "grad_norm": 8.579697608947754,
      "learning_rate": 1.6157973436537955e-05,
      "loss": 0.5562,
      "step": 8200
    },
    {
      "epoch": 0.6993006993006993,
      "grad_norm": 5.3733696937561035,
      "learning_rate": 1.571818101855924e-05,
      "loss": 0.5812,
      "step": 8300
    },
    {
      "epoch": 0.7077260089308282,
      "grad_norm": 5.648740291595459,
      "learning_rate": 1.5278388600580525e-05,
      "loss": 0.5513,
      "step": 8400
    },
    {
      "epoch": 0.7161513185609572,
      "grad_norm": 4.6416192054748535,
      "learning_rate": 1.4838596182601814e-05,
      "loss": 0.4962,
      "step": 8500
    },
    {
      "epoch": 0.724576628191086,
      "grad_norm": 3.8472354412078857,
      "learning_rate": 1.4398803764623098e-05,
      "loss": 0.5436,
      "step": 8600
    },
    {
      "epoch": 0.7330019378212149,
      "grad_norm": 4.559928894042969,
      "learning_rate": 1.3959011346644385e-05,
      "loss": 0.5632,
      "step": 8700
    },
    {
      "epoch": 0.7414272474513438,
      "grad_norm": 2.702608346939087,
      "learning_rate": 1.351921892866567e-05,
      "loss": 0.548,
      "step": 8800
    },
    {
      "epoch": 0.7498525570814727,
      "grad_norm": 6.475100040435791,
      "learning_rate": 1.3079426510686957e-05,
      "loss": 0.5643,
      "step": 8900
    },
    {
      "epoch": 0.7582778667116017,
      "grad_norm": 5.797354698181152,
      "learning_rate": 1.2639634092708242e-05,
      "loss": 0.5376,
      "step": 9000
    },
    {
      "epoch": 0.7667031763417306,
      "grad_norm": 5.18259334564209,
      "learning_rate": 1.2199841674729529e-05,
      "loss": 0.5476,
      "step": 9100
    },
    {
      "epoch": 0.7751284859718595,
      "grad_norm": 3.281127691268921,
      "learning_rate": 1.1760049256750814e-05,
      "loss": 0.5189,
      "step": 9200
    },
    {
      "epoch": 0.7835537956019883,
      "grad_norm": 4.38146448135376,
      "learning_rate": 1.13202568387721e-05,
      "loss": 0.513,
      "step": 9300
    },
    {
      "epoch": 0.7919791052321172,
      "grad_norm": 6.974907875061035,
      "learning_rate": 1.0880464420793386e-05,
      "loss": 0.5649,
      "step": 9400
    },
    {
      "epoch": 0.8004044148622462,
      "grad_norm": 7.185014247894287,
      "learning_rate": 1.0440672002814672e-05,
      "loss": 0.5664,
      "step": 9500
    },
    {
      "epoch": 0.8088297244923751,
      "grad_norm": 6.088490962982178,
      "learning_rate": 1.0000879584835959e-05,
      "loss": 0.5406,
      "step": 9600
    },
    {
      "epoch": 0.817255034122504,
      "grad_norm": 9.866458892822266,
      "learning_rate": 9.561087166857244e-06,
      "loss": 0.523,
      "step": 9700
    },
    {
      "epoch": 0.8256803437526329,
      "grad_norm": 7.540380477905273,
      "learning_rate": 9.12129474887853e-06,
      "loss": 0.5153,
      "step": 9800
    },
    {
      "epoch": 0.8341056533827618,
      "grad_norm": 6.534494876861572,
      "learning_rate": 8.681502330899816e-06,
      "loss": 0.5412,
      "step": 9900
    },
    {
      "epoch": 0.8425309630128908,
      "grad_norm": 5.825223922729492,
      "learning_rate": 8.241709912921101e-06,
      "loss": 0.544,
      "step": 10000
    },
    {
      "epoch": 0.8509562726430197,
      "grad_norm": 5.354305267333984,
      "learning_rate": 7.801917494942387e-06,
      "loss": 0.5312,
      "step": 10100
    },
    {
      "epoch": 0.8593815822731485,
      "grad_norm": 4.071351051330566,
      "learning_rate": 7.362125076963673e-06,
      "loss": 0.5211,
      "step": 10200
    },
    {
      "epoch": 0.8678068919032774,
      "grad_norm": 6.298977851867676,
      "learning_rate": 6.922332658984959e-06,
      "loss": 0.5704,
      "step": 10300
    },
    {
      "epoch": 0.8762322015334063,
      "grad_norm": 4.4587578773498535,
      "learning_rate": 6.482540241006245e-06,
      "loss": 0.5561,
      "step": 10400
    },
    {
      "epoch": 0.8846575111635353,
      "grad_norm": 4.273247241973877,
      "learning_rate": 6.042747823027531e-06,
      "loss": 0.5345,
      "step": 10500
    },
    {
      "epoch": 0.8930828207936642,
      "grad_norm": 10.41765022277832,
      "learning_rate": 5.602955405048817e-06,
      "loss": 0.5724,
      "step": 10600
    },
    {
      "epoch": 0.9015081304237931,
      "grad_norm": 6.493641376495361,
      "learning_rate": 5.1631629870701035e-06,
      "loss": 0.5588,
      "step": 10700
    },
    {
      "epoch": 0.909933440053922,
      "grad_norm": 7.358182907104492,
      "learning_rate": 4.72337056909139e-06,
      "loss": 0.5339,
      "step": 10800
    },
    {
      "epoch": 0.9183587496840508,
      "grad_norm": 4.382004737854004,
      "learning_rate": 4.283578151112675e-06,
      "loss": 0.5427,
      "step": 10900
    },
    {
      "epoch": 0.9267840593141798,
      "grad_norm": 4.13134765625,
      "learning_rate": 3.848183657313748e-06,
      "loss": 0.5519,
      "step": 11000
    },
    {
      "epoch": 0.9352093689443087,
      "grad_norm": 8.39721393585205,
      "learning_rate": 3.408391239335034e-06,
      "loss": 0.5333,
      "step": 11100
    },
    {
      "epoch": 0.9436346785744376,
      "grad_norm": 3.817809820175171,
      "learning_rate": 2.9685988213563198e-06,
      "loss": 0.4901,
      "step": 11200
    },
    {
      "epoch": 0.9520599882045665,
      "grad_norm": 11.631340980529785,
      "learning_rate": 2.528806403377606e-06,
      "loss": 0.5329,
      "step": 11300
    },
    {
      "epoch": 0.9604852978346954,
      "grad_norm": 5.026363849639893,
      "learning_rate": 2.0890139853988916e-06,
      "loss": 0.5518,
      "step": 11400
    },
    {
      "epoch": 0.9689106074648244,
      "grad_norm": 3.8652477264404297,
      "learning_rate": 1.6492215674201777e-06,
      "loss": 0.5141,
      "step": 11500
    },
    {
      "epoch": 0.9773359170949533,
      "grad_norm": 4.519871711730957,
      "learning_rate": 1.2094291494414636e-06,
      "loss": 0.5407,
      "step": 11600
    },
    {
      "epoch": 0.9857612267250822,
      "grad_norm": 5.15070915222168,
      "learning_rate": 7.696367314627496e-07,
      "loss": 0.5317,
      "step": 11700
    },
    {
      "epoch": 0.994186536355211,
      "grad_norm": 5.389969825744629,
      "learning_rate": 3.2984431348403557e-07,
      "loss": 0.5416,
      "step": 11800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7562328182766139,
      "eval_loss": 0.5283420085906982,
      "eval_runtime": 140.6272,
      "eval_samples_per_second": 150.028,
      "eval_steps_per_second": 9.379,
      "step": 11869
    }
  ],
  "logging_steps": 100,
  "max_steps": 11869,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.013625126851994e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
