## hw3

Результаты работы: 

1. Были выбраны предобученная модель DeepPavlov/rubert-base-cased от Hugging Face и набор данных MonoHime/ru_sentiment_dataset, предназначенный для задач анализа тональности.
   
2. Модель была дообучена на данном наборе данных с использованием LoRA, что позволило значительно увеличить скорость обучения при сохранении хорошей точности. Итоговая оценочная точность (eval_accuracy) составила 0.76. Ожидается, что при увеличении количества epoch и повышении ранга LoRA (LoRA rank) точность еще более возрастет. (Код этапа обучения модели находится в файле hw3.ipynb).
   
3. Были загружены веса обученного LoRA-адаптера и применены к базовой модели для выполнения инференса (sentiment_analyze.py). В качестве данных использовались ранее собранные отзывы с Ozon (ozon_reviews), которые были предварительно обработаны (удалены имена, каждый отзыв сохранен в одной строке). Затем часть этих отзывов была загружена для проведения анализа тональности. Результаты представлены на рисунке ниже.
   ![pic1](results\pic.png)

4. Результаты выглядят достаточно хорошо, однако было замечено, что большинство отзывов классифицируются как «NEUTRAL», небольшая часть – как «POSITIVE», и практически отсутствуют отзывы, классифицированные как «NEGATIVE». Во многом это объясняется обучающим набором данных, в котором только крайне негативные отзывы были отнесены к категории «NEGATIVE», а также тем, что часть данных в нем была классифицирована неверно.